{
  "training": {
    "deterministic": {
      "name": "deterministic",
      "type": "checkbox",
      "description": "Should the training be deterministic?"
    },
    "launch": {
      "name": "launch",
      "type": "radio",
      "description": "Run the training with torch.distributed.launch (recommended)"
    },
    "spawn": {
      "name": "spawn",
      "type": "radio",
      "description": "Run the training with torch.multiprocessing.spawn"
    },
    "nproc_per_node": {
      "name": "nproc_per_node",
      "type": "number",
      "description": "Number of processes to launch on each node (mandatory for single node, multi gpus distributed training)",
      "min": 1,
      "default": 2
    },
    "nnodes": {
      "name": "nnodes",
      "type": "number",
      "description": "Number of nodes to use for distributed training (mandatory for multi nodes, multi gpus distributed training)",
      "min": 1,
      "default": 1
    },
    "master_addr": {
      "name": "master_addr",
      "type": "text",
      "description": "Master node TCP/IP address for torch native backends (mandatory if you have filled number of nodes)",
      "default": "127.0.0.1"
    },
    "master_port": {
      "name": "master_port",
      "type": "number",
      "description": "Master node port for torch native backends (mandatory if you have filled number of nodes)",
      "min": 0,
      "default": 8080
    }
  },
  "handlers": {
    "save_training": {
      "name": "save_training",
      "type": "checkbox",
      "description": "Save the training state (models, optimizers, trainers, ...) by every save_every_iters."
    },
    "save_evaluation": {
      "name": "save_evaluation",
      "type": "checkbox",
      "description": "Save the model(s) by best evaluation metric score."
    },
    "terminate_on_nan": {
      "name": "terminate_on_nan",
      "type": "checkbox",
      "description": "Stop the training if there is Inf/NaN tensor found."
    },
    "timer": {
      "name": "timer",
      "type": "checkbox",
      "description": "Measure (average) time between events using Timer handler."
    },
    "patience": {
      "name": "patience",
      "type": "number",
      "description": "Number of events to wait if no improvement and then stop the training."
    },
    "filename_prefix": {
      "name": "filename_prefix",
      "type": "text",
      "value": "checkpointing",
      "description": "What prefix would you like to put in front of saved checkpoint file? (mandatory for saving training states)"
    },
    "save_every_iters": {
      "name": "save_every_iters",
      "type": "number",
      "value": "checkpointing",
      "description": "Iteration interval for saving training states (mandatory for saving training states)"
    },
    "n_saved": {
      "name": "n_saved",
      "type": "number",
      "value": "checkpointing",
      "description": "How many checkpoint file would you like to keep on disk? (mandatory for saving both training and evaluation)"
    },
    "limit_sec": {
      "name": "limit_sec",
      "type": "number",
      "description": "How long do you want to run for the training and then terminate? (in seconds)"
    }
  },
  "loggers": {
    "output_dir": {
      "name": "output_dir",
      "type": "text",
      "description": "Directory to save all outputs",
      "default": "./logs"
    },
    "log_every_iters": {
      "name": "log_every_iters",
      "type": "number",
      "description": "Logging interval for training statistics",
      "default": 2
    },
    "logger": {
      "name": "logger",
      "type": "array",
      "description": "Select experiment tracking system",
      "options": [
        "clearml",
        "mlflow",
        "neptune",
        "polyaxon",
        "tensorboard",
        "visdom",
        "wandb"
      ]
    }
  }
}
